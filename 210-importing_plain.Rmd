---
output:
  pdf_document: default
  html_document: default
---



```{r setup_ch210, include=FALSE, eval=TRUE}

source("package_load.R")

```


# Importing data: plain-text files {#importing-plaintext}

In this chapter:

* Importing data from plain text files




## Delimited plain text files

Plain-text (sometimes called "ASCII files", after the character encoding standard they use) files are often used to share data. They are limited in what they can contain, which has both downsides and upsides. On the downside, they can't carry any additional information with them, such as variable types and labels. But on the upside, they don't carry any additional information that requires additional interpretation by the software. This means they can be read consistently by a wide variety of software tools.

Plain text files come in two varieties: delimited and fixed-width. "Delimited" is a reference to the fact that the files have a character that marks the boundary between two variables. A very common delimited format is the CSV file; the letters in the file name stand for "Comma Separated Values", and use a comma as the variable delimiter. Another delimited type, somewhat less common, uses the tab character to separate the variables, and will have the extension "TSV" for, you guessed it, "Tab Separated Values". Occasionally you will find files that use semi-colons, colons, or spaces as the delimiters.



### Using base R

Base R [@R-base] has a number of functions to read CSV, TSV, and fixed-width files.

For example, `read.csv()` is a base R function to read CSV files.


```{r}
# example
# assign path using the {here} package
penguins_path <- here::here("data", "penguins.csv")

# read the contents of the CSV file
penguins_data <- read.csv(penguins_path)
```


```{r penguins_csv, echo=FALSE, eval=FALSE}
# alternative approach with {dpjr} package
library(dpjr)
penguins_path <- dpjr_data("penguins.csv")

penguins_data <- read.csv(penguins_path)

```



### Using {readr} (tidyverse)

The {readr} [@R-readr] package is part of the tidyverse, and has some advantages over the base R functions when it comes to plain-text files.

We activate {readr} by using the `library()` function:

```{r, eval=FALSE}
library(readr)
```


This chunk creates a string object that contains the path name, and then uses the function `read_csv()` to create an object called `penguins_data`, from a CSV file of the same name.

* Note: this is `read` _underscore_ `csv`, not base R's `read` _dot_ `csv`.

The `read_csv()` function is quite a bit faster with big data files, and has some useful flexibility when it comes to defining variable types as part of the read function (rather than reading in the data, and then altering the variable types). As well, it returns a tibble instead of a data frame. (For information about the difference, see [@Wickham_Grolemund2016, Tibbles])

```{r}
# read the file and assign it to the object "penguins_data"
# note that this uses the "penguins_path" object created earlier
penguins_data <- read_csv(penguins_path)

```

The function returns a message letting us know the type that each variable is assigned.

Adding the `col_types = cols()` parameter allows us to alter what {readr} has decided for us. For example, we could set the `species` variable to be an factor.

When we show the entire table, we can see that the variable `species` is now a factor type.

```{r}
penguins_data <- read_csv(penguins_path,
                   col_types =
                     cols(species = col_factor()))
penguins_data
```



The {readr} package allows a lot of control over how the file is read. Of particular utility are 

* `na = ""` -- specify which values you want to be turned into `NA`

* `skip = 0` -- specify how many rows to skip 

* `n_max = Inf` -- the maximum number of records to read


For example, if we were working with a very large file and wanted to read the first five rows, just to see what's there, we could write the following:

```{r}
read_csv(penguins_path, 
         n_max = 5)
```


## Fixed-width files 

Fixed-width files don't use a delimiter, and instead specify which column(s) each variable occupies, consistently for every row in the entire file.

Fixed-width files are a hold-over from the days when storage was expensive and/or on punch cards. This meant that specific columns in the table (or card) were assigned to a particular variable, and precious space was not consumed with a delimiter. Compression methods have since meant that a CSV file with unfixed variable lengths are more common, but in some big data applications, fixed-width files can be much more efficient.

If you ever have to deal with a fixed-width file, you will (or should!) receive a companion file letting you know the locations of each variable in every row.

In this example, we will use the one provided in the {dpjr} package, `authors_fwf.txt`. This code chunk assigns the path to the file location, which we can use in our code later.


```{r importing_authors_path}
authors_path <- dpjr::dpjr_data("authors_fwf.txt")
```


This simple file has four (or as we will see, sometimes three, if we combine first and last name as one) variables, and three records (or rows).

* first name

* last name

* U.S. state of birth (two-letter abbreviation)

* randomly generated unique ID

If we open the file in a text editor, we see this:

![authors_fwf.txt](img/authors_img.jpg)



The first approach would be to allow {readr} to guess where the column breaks are. The `fwf_empty()` function looks through the specified file and returns the beginning and ending locations it has guessed, as well as the `skip` value that the `read_fwf()` function uses.

Note that the column names are specified in a list. 



```{r importing_authors_path_2}
fwf_empty(authors_path, col_names = c("first", "last", "state", "unique_id"))
```

That information can then be used by the `read_fwf()` function:

```{r importing_authors_path_3}

read_fwf(authors_path, 
         fwf_empty(authors_path, 
                   col_names = c("first", "last", "state", "unique_id")))

```


Note that {readr} will impute the variable type, as it did with the CSV file. And although we won't implement it in these examples, in the same way `read_fwf()` allows us to use the `col_types` specification, as well as `na`, `skip`, and others. See the `read_fwf()` reference at https://readr.tidyverse.org/reference/read_fwf.html for all the details.


Reading this fixed-width file with these three author names worked, but it could break quite easily. We just need one person with a three or more components to their name (initials, spaces, or hyphens, as in [Ursula K. Le Guin](https://en.wikipedia.org/wiki/Ursula_K._Le_Guin) or [Ta-Nehisi Coates](https://en.wikipedia.org/wiki/Ta-Nehisi_Coates)), or some missing values, and the inconsistent structure throws off the `read_fwf()` parser.

In this example, we read a longer list of author names:

```{r importing_authors2_path_}
authors2_path <- dpjr::dpjr_data("authors2_fwf.txt")

fwf_empty(authors2_path, 
                   col_names = c("first", "last", "state", "unique_id"))

```

The `fwf_empty()` function found only three columns, as shown in the "begin" and "end" values that are returned.

When we use the read function, it finds three columns:

```{r}
read_fwf(dpjr::dpjr_data("authors2_fwf.txt"))
```


Adding the `col_names =` argument now mis-identifies the variables.

```{r}

read_fwf(authors2_path, 
         fwf_empty(authors2_path, 
                   col_names = c("first", "last", "state", "unique_id")))

```

A more reliable approach is to specify exactly the width of each column. Note that in the example below, we specify only "name" without splitting it into first and last.

The variables and their widths are as follows:


Variable           Width   Start position   End position
--------           -----   --------------   ------------
name               20       1               20
state              10       21              30
uniqueID           12       31              42


Visually, the file looks like this:


![fwf-sample.txt](img/names_columns.png)


Those column positions can also be used to determine the width of each variable:


![fwf-sample.txt](img/names_arrows.png)

The widths can be added to the `fwf_widths` argument:

```{r}

read_fwf(authors2_path, 
         fwf_widths(c(20, 10, 12), c("name", "state", "unique_id")))

```

A third option is to provide two lists of locations using `fwf_positions()`, the first with the start positions, and the second with the end positions. The first variable "name" starts at position 1 and ends at position 20, and the second variable "ssn" starts at 30 and ends at 42. Note that we won't read the "state" variable which occupies the ten columns from 21 through 29.

```{r}
read_fwf(authors2_path, 
         fwf_positions(c(1, 31), c(20, 42), c("name", "unique_id")))
```

The fourth option is a syntactic variation on the third, with the same values but in a different order. This time, all of the relevant information about each variable is aggregated, with the name followed by the start and end locations.

```{r}

read_fwf(authors2_path, 
         fwf_cols(name = c(1, 20), unique_id = c(31, 42)))

```

And finally, {readr} provides a fifth way to read in a fixed-width file that is a variation on the second approach we saw, with the name and the width values aggregated.

```{r}

read_fwf(authors2_path, 
         fwf_cols(name = 20, state = 10, unique_id = 12))

```



### An extreme example of a fixed-width file 

A particularly interesting research question is the relationship between education level and different health outcomes. In this example, we will start the process of importing a large file that contains data that will allow us to explore whether there is a correlation.  

Statistics Canada has made available a Public-Use Microdata File (PUMF) of the Joint Canada/United States Survey of Health (JCUSH)\index{Joint Canada/United States Survey of Health (JCUSH)}, a telephone survey conducted in late 2002 and early 2003. There were 8,688 respondents to the survey, 3,505 Canadians and 5,183 Americans. The data file that is available is anonymized, so we have access to the individual responses, which will facilitate additional analysis.

The webpage for the survey, including the PUMF file, data dictionary, and methodological notes, is here:
https://www150.statcan.gc.ca/n1/pub/82m0022x/2003001/4069119-eng.htm

The PUMF is a fixed-width file named "JCUSH.txt". This file is quite a lot larger than the author names example above. There are the 8,688 records and each line of data takes up 552 columns! 

Here's what the first 40 characters of the first record looks like:


```{r jcush_txt_readlines, eval=FALSE}
readLines(dpjr::dpjr_data("JCUSH.txt"), n = 1)
```

```{r jcush_txt_readlines_truncate, echo=FALSE}

str_sub(readLines(dpjr::dpjr_data("JCUSH.txt"), n = 1), 1, 40)

```

There's not a bit of white space anywhere in this data file!

Let's imagine that our research goal is to determine if there is a relationship between a person's level of education and their health outcomes. We've reviewed the data documentation, and it's clear that the JCUSH data has what we need. 

Here's how one variable, highest level of post-secondary education achieved, appears in the data dictionary:


![health survey example](img/healthsurv_var_postsec.JPG)

The variable "SDJ1GHED" is 1 character long, in position 502 of the data. The variable might be only 1 character long, but when coupled with the information in the "Content" column, it becomes a very powerful piece of information. 

For our analysis question, we will read in four variables: the unique respondent identification number, the country, the overall health outcomes, and education level. For the variable names, we will use the same ones used in the data dictionary:

| Name | Variable | Length | Position |
| :--- | :---     | :---:  | :---:  |
| SAMPLEID | Household identifier | 12 | 1 - 12 |
| SPJ1_TYP | Sample type [country] | 1 | 13 |
| GHJ1DHDI | Health Description Index | 1 | 32 |
| SDJ1GHED | Highest level of post-secondary education attained | 1 | 32 |


You will note in the code below that in the case of the variables that are of length "1", the code the start and end positions are the same.

As well, the `SAMPLEID` variable is a 12-digit number; the `read_fwf()` will interpret this as variable type double, and represent it in scientific notation. To be useful, we want to be able to see and evaluate the entire string. As a result, we use `col_types()` to specify `SAMPLEID` as a character.

```{r jcush_txt_read_vars}

jcush <- readr::read_fwf(dpjr::dpjr_data("JCUSH.txt"), 
         fwf_cols(
           SAMPLEID = c(1, 12),
           SPJ1_TYP = c(13, 13), 
           GHJ1DHDI = c(32, 32),
           SDJ1GHED = c(502, 502)
           ),
         col_types = list(
           SAMPLEID = col_character()
         ))

head(jcush)

```

Imagine, though, the challenge of handling this amount of data at one time! Between the many variables and the complex value labels, the "data" is more than just the fixed-width file. This is a circumstance where a different data storage solution ([as we will see later](#700_labelled_factors)) might have some strengths.




<!-- 
This file by Martin Monkman is licensed under a Creative Commons Attribution 4.0 International License. 
-->

