---
output:
  pdf_document: default
  html_document: default
---


<!-- 
This file by Martin Monkman is licensed under a Creative Commons Attribution 4.0 International License. 
-->



```{r setup_ch500, include=FALSE}

# packages

```


# Clean data principles {#clean-data}

In this chapter:

* Understanding what makes data “dirty”, and why context matters

* The principles of data quality, and how dirty data is part of data quality

* Understanding tidy data principles

* Serving the research question




## Why clean data matters


We've read in our raw data. The next step is to make sure that the data is what we expect, and what we need for our analysis. This is important, in that it ensures that our analysis is going to be accurate, and the consistency of our values gives us the ability to link to other data sources.


Sometimes, we will see this questions framed as whether or not the data is _dirty_, and whether it needs _cleaning_.



### Data quality literature

There is quite a lot of literature on how to define data quality. The concepts in the hierarchical dimensions described by Wang, Reddy and Kon [@WangRichardY.1995TqdA] are as follows:

* Accessible

* Interpretable

* Useful

* Believable

"Dirty data" is data that falls short on the _believable_ dimension, in particular evaluating whether the data are complete, consistent, and accurate. It is important to note that these categories are not mutually exclusive; a variable might be simultaneously inconsistent and inaccurate.

**Complete**

For our purposes, "complete" means whether any values in each record are missing (internally complete).

"Complete" does not mean that every possible member of the population is represented in the data. With a well-designed sample, it is possible that a sub-set of the population can provide an accurate set of measures about the population. Furthermore, it is possible to determine whether the records are an accurate representation of the whole.

[SAMPLING THEORY -- validating a sample]

**Consistent**

We will consider a measure to be consistent if the same value is reported in the same way.

Some examples:

* Units are consistent. One example is temperature, and ensuring that the values are consistently reporting in degrees Celsius, not mixing Farenheit and Kelvin. Another might be in a survey or form with an international audience, where `salary` might be completed by respondents in the values of their local currency.

* Spelling is consistent. My home province in Canada is "British Columbia", but is often abbreviated to "B.C." or "BC". Or the 57 different ways to spell "Philadelphia". ^[In this tweet, you can see 57 different ways of spelling "Philadelphia" in the data collected in a US Government loan form (https://twitter.com/dataeditor/status/1280278987797942272?s=20)]

* In some cases, the mode of data collection can introduce differences in the value recorded. This can apply to everything from variability of scientific instruments such as air quality sensors [@Khreis_etal_2022] to how people respond to surveys conducted in different media [@Abeysundera_2015] [@Holbrook_Green_Krosnick_2003] [@St-Pierre_Beland_2004].



**Accurate**

When we say accurate, we mean that the value recorded in our data is the value measured.

Some examples of inaccurate data are:

* The use of a default value in place of a missing or "unknown" value. This is sometimes embedded in the data collection or database software, leading to values that should have been "unknown" be entered as the default.

> Dr Davis Lawrence, director of safety-literature database the SafeLit Foundation...tells me that 'in most US states the quality of police crash reports is at best poor for use as a research tool. ... Data-quality checks were rare and when quality was evaluated it was found wanting. For example, in Louisiana for most crashes in the 1980s most of the occupants were males who were born on January 1st, 1950. Almost all of the vehicles involved in crashes were the 1960 model year.' Except they weren't. These were just the default settings. [@Criado_Perez_2019, p.190]



* A data entry error. Perhaps the most common are typographical errors, where the wrong value is entered. Another type is what we might call a "variable transposition error" (where the value is transposed one column over, something that happens all too often with address records, where the city name might end up in the state/province column).

* Values are transformed automagically by software. Microsoft's Excel spreadsheet program is the most famous of these, converting many non-date values into date format, and assigning new values to store the data. For example, entering the character string "SEPT1" gets converted to September 1st of the current year. There is documented evidence that this software behaviour has caused errors in gene research. [@Zeeberg_etal_2004], [@Abeysooriya_etal_2021]


* Dates may be stored as a numeric value (or "serial number") representing the number of days elapsed from a fixed starting point—a starting point that varies by operating system. For example, Excel for Windows uses January 1, 1900 as the first day, while earlier versions Macintosh computers, and by extension Excel for Macintosh, used January 1, 1904 as the start date. Thus the same date would be stored as different values. ^["Differences between the 1900 and the 1904 date system in Excel"](https://docs.microsoft.com/en-us/office/troubleshoot/excel/1900-and-1904-date-system)

```{r}
readxl::read_excel("date.xlsx", col_types = "text")

lubridate::today() - 44571
```



* Contradiction (for example, imagine that a single individual is entered into two databases, but when we compare them we see that the date of birth differs, perhaps due to non-ISO8601 entry: 07-08-79 and 08-07-79 both have the same digits but one could be mm-dd-yy and the other dd-mm-yy...we just don't know which is the correct one. Or is one a typo?)


* Other (I'm not sure how to characterize this—wikipedia uses the term "cultural ignorance" which might fit)

> "Prawo Jazdy" was a supposed Polish national who was listed by the Garda Síochána in a police criminal database as having committed more than 50 traffic violations in Ireland. A 2007 memorandum stated that an investigation revealed prawo jazdy [ˈpra.vɔ ˈjaz.dɨ] to be Polish for 'driving licence', with the error arising due to officers mistaking the phrase, printed on Polish driving licences, to be a personal name while issuing traffic tickets. [@wiki:prawo_jazdy]


Other common dirty data problems that fall outside the four broad data quality categories include:

* Column headers are values instead of variable names, or there are duplicate variable names.

* Multiple data types in a column. For example, some records are numbers and some are character strings—and this could be entirely correct, but if some number entry includes commas as thousands separators, it might be stored as a character.

* Multiple variables are stored in one column (examples include first name & last name, city & province or state).





See 

* [@Zumel_Mount_2019, chapters 3 and 4]


* [@Ligon_1996], [@Ligon_2015], [@Ligon_2007] 

* [@DAgostinoMcGowan_Peng_Hicks_2022]


***

## Cleaning the data

If the data fails to meet our standards or quality, we need to _clean the data_. Which doesn't sound like a lot of fun. Didn't we want to be data scientists or business intelligence experts or academic scientists uncovering the insights hiding in the data? Don't we want to be _doing analysis_? 

There is a strong argument to be made that the process of cleaning data is a fundamental part of the analytic process, or the corresponding statement that any analytic process requires data cleaning.

Randy Au has written "The act of cleaning data imposes values/judgments/interpretations upon data intended to allow downstream analysis algorithms to function and give results. That’s exactly the same as doing data analysis. In fact, “cleaning” is just a spectrum of reusable data transformations on the path towards doing a full data analysis." [@Au_data_cleaning_2020]

At this point we should ask what are we doing when we say we are "cleaning the data"? And how can we confirm that it is "cleaned" in the way that we have defined?


**The first challenge**: How do we find these things?

**The second challenge**: What can and should we do about them?


See [@Greve_Clean_data]


## Structure

The first place to start with cleaning your data is the structure. 


### Tidy data

Tidy data\index{tidy data}

[@tidydata]





## Exploratory data analysis

One way to identify dirty data is through the process of _exploratory data analysis_ (EDA). [@Tukey_1977] This process is, first and foremost, intended to help guide our analysis, but it has the additional benefit of providing clues about the ways that our data is dirty.

EDA consists of two groups of techniques:

* summary statistics

* data visualization

### Summary statistics

(need to revise data set)

```{r}

# read in the data
customer_data <- readRDS("data_temp/custdata.RDS")

```

We can use R's `summary()` function to quickly get a glimpse of the data.

The things to look for:

* missing values

* invalid values and outliers

* data ranges that are too wide or too narrow

* the units of the data

```{r}
summary(customer_data)
```

### Data visualization

A plot can show us a wealth of information that cannot be expressed in the summary statistics. Here's the `age` variable from the customer data:

```{r}

summary(customer_data$age)

```



And here is a density plot that shows the distribution of customers by their age.


```{r}

ggplot(customer_data, aes(x = age)) +
  geom_density(bw = .75)

```



Here are some questions that we might want to explore further in the `age` variable, after seeing the results of the `summary()` function and the plot:

* The maximum age is 120—perhaps you are already aware of the fact that only one person whose age has been independently verified lived long enough to celebrate their 120th birthday (they were 122 years, 164 days old when they passed away). [Wikipedia, "List of the verified oldest people"](https://en.wikipedia.org/wiki/List_of_the_verified_oldest_people)

* Why is there a sudden cluster of customers age 95? We would expect this to be a relatively smooth line from one age category to the next.



In the next chapter, we will look in more depth at ways to identify dirty elements in your data.




